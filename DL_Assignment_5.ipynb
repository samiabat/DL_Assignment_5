{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eebB3YXUP6H5",
        "outputId": "12310539-6f9f-4655-c3a9-3309d731d7a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activation2 Output: tensor([[0.5000, 0.5000]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "class DenseLayer:\n",
        "    def __init__(self, n_inputs, n_neurons):\n",
        "        self.weights = 0.01 * torch.rand(n_inputs, n_neurons)\n",
        "        self.biases = torch.zeros((1, n_neurons))\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.output = torch.matmul(inputs, self.weights) + self.biases\n",
        "        return self.output\n",
        "\n",
        "class ActivationReLU:\n",
        "    def forward(self, inputs):\n",
        "        self.output = torch.relu(inputs)\n",
        "        return self.output\n",
        "\n",
        "class ActivationSigmoid:\n",
        "    def forward(self, inputs):\n",
        "        self.output = torch.sigmoid(inputs)\n",
        "        return self.output\n",
        "class ActivationSoftmax:\n",
        "    def forward(self, inputs):\n",
        "        self.output = torch.nn.functional.softmax(inputs, dim=1)\n",
        "        return self.output\n",
        "\n",
        "# Input data\n",
        "X = torch.tensor([0.4, 0.9])\n",
        "\n",
        "# Create layers and activations\n",
        "hidden_layer_1 = DenseLayer(2, 2)\n",
        "activation1 = ActivationReLU()\n",
        "output_layer = DenseLayer(2, 2)\n",
        "activation2 = ActivationSigmoid()\n",
        "\n",
        "# Forward pass\n",
        "hidden_layer_1_output = hidden_layer_1.forward(X)\n",
        "activation1_output = activation1.forward(hidden_layer_1_output)\n",
        "output_layer_output = output_layer.forward(activation1_output)\n",
        "activation2_output = activation2.forward(output_layer_output)\n",
        "\n",
        "print(\"Activation2 Output:\", activation2_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(predictions, targets):\n",
        "    if predictions.shape[-1] > 1:\n",
        "        _, predicted_classes = torch.max(predictions, 1)\n",
        "    else:\n",
        "        predicted_classes = torch.round(predictions)\n",
        "\n",
        "    correct_predictions = (predicted_classes == targets).sum().item()\n",
        "    total_samples = len(targets)\n",
        "\n",
        "    accuracy_value = (correct_predictions / total_samples) * 100.0\n",
        "\n",
        "    return accuracy_value\n",
        "def mean_squared_error(predictions, targets):\n",
        "    return torch.mean((predictions - targets)**2)"
      ],
      "metadata": {
        "id": "4txVRuS4RgVa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def back_propagation(X, y, lr=0.01):\n",
        "    # Forward pass\n",
        "    hidden_layer_1_output = hidden_layer_1.forward(X)\n",
        "    activation1_output = activation1.forward(hidden_layer_1_output)\n",
        "    hidden_layer_2_output = hidden_layer_2.forward(activation1_output)\n",
        "    activation2_output = activation2.forward(hidden_layer_2_output)\n",
        "    output_layer_output = output_layer.forward(activation2_output)\n",
        "\n",
        "    # Backward pass\n",
        "    back_output = output_layer_output - y\n",
        "    back_hidden_2 = torch.matmul(back_output, output_layer.weights.t()) * (hidden_layer_2_output > 0).float()\n",
        "    back_hidden_1 = torch.matmul(back_hidden_2, hidden_layer_2.weights.t()) * (hidden_layer_1_output > 0).float()\n",
        "\n",
        "    # Update weights and biases\n",
        "    output_layer.weights -= lr * torch.matmul(activation2_output.t(), back_output)\n",
        "    output_layer.biases -= lr * back_output.sum(dim=0, keepdim=True)\n",
        "\n",
        "    hidden_layer_2.weights -= lr * torch.matmul(activation1_output.t(), back_hidden_2)\n",
        "    hidden_layer_2.biases -= lr * back_hidden_2.sum(dim=0, keepdim=True)\n",
        "\n",
        "    hidden_layer_1.weights -= lr * torch.matmul(X.reshape(1, -1).t(), back_hidden_1)\n",
        "    hidden_layer_1.biases -= lr * back_hidden_1.sum(dim=0, keepdim=True)\n",
        "\n",
        "# Input data\n",
        "X = torch.tensor([0.4, 0.9]).reshape(1, -1)\n",
        "y = torch.tensor([1, 0]).reshape(1, -1)\n",
        "\n",
        "# Create layers and activations\n",
        "hidden_layer_1 = DenseLayer(2, 2)\n",
        "activation1 = ActivationReLU()\n",
        "hidden_layer_2 = DenseLayer(2, 2)\n",
        "activation2 = ActivationReLU()\n",
        "output_layer = DenseLayer(2, 2)\n",
        "softmax_activation = ActivationSoftmax()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(1000):\n",
        "    # Forward and backward pass\n",
        "    back_propagation(X, y)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        # Print loss and accuracy every 100 epochs\n",
        "        hidden_layer_1_output = hidden_layer_1.forward(X)\n",
        "        activation1_output = activation1.forward(hidden_layer_1_output)\n",
        "        hidden_layer_2_output = hidden_layer_2.forward(activation1_output)\n",
        "        activation2_output = activation2.forward(hidden_layer_2_output)\n",
        "        output_layer_output = output_layer.forward(activation2_output)\n",
        "\n",
        "        loss = mean_squared_error(output_layer_output, y)\n",
        "        acc = accuracy(output_layer_output, torch.round(y))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss.item()}, Accuracy: {acc}%\")\n",
        "\n",
        "# Test the final output\n",
        "hidden_layer_1_output = hidden_layer_1.forward(X)\n",
        "activation1_output = activation1.forward(hidden_layer_1_output)\n",
        "hidden_layer_2_output = hidden_layer_2.forward(activation1_output)\n",
        "activation2_output = activation2.forward(hidden_layer_2_output)\n",
        "final_output = output_layer.forward(activation2_output)\n",
        "final_softmax = softmax_activation.forward(final_output)\n",
        "\n",
        "print(\"Final Output:\", final_output)\n",
        "print(\"Final Softmax Output:\", final_softmax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMdHrEE_P7IY",
        "outputId": "86b95435-ec76-4a24-da80-d4477f495032"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.4900476634502411, Accuracy: 100.0%\n",
            "Epoch 100, Loss: 0.0656316950917244, Accuracy: 100.0%\n",
            "Epoch 200, Loss: 0.0087873674929142, Accuracy: 100.0%\n",
            "Epoch 300, Loss: 0.0011762842768803239, Accuracy: 100.0%\n",
            "Epoch 400, Loss: 0.0001574439520481974, Accuracy: 100.0%\n",
            "Epoch 500, Loss: 2.1073941752547398e-05, Accuracy: 100.0%\n",
            "Epoch 600, Loss: 2.820472673192853e-06, Accuracy: 100.0%\n",
            "Epoch 700, Loss: 3.776120820475626e-07, Accuracy: 100.0%\n",
            "Epoch 800, Loss: 5.048337570201511e-08, Accuracy: 100.0%\n",
            "Epoch 900, Loss: 6.7476868537141854e-09, Accuracy: 100.0%\n",
            "Final Output: tensor([[9.9996e-01, 7.4346e-08]])\n",
            "Final Softmax Output: tensor([[0.7311, 0.2689]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ibVSQOrlQJME"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}